{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "751b6abb384d0de",
   "metadata": {},
   "source": [
    "# Use the transformer to generate optimized antibodies by means of a genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "from typing import List, Dict, Tuple, Optional, Set\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from models.antibody_transformer import AntibodyTransformer\n",
    "from anarci import run_anarci\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class GenerationConfig:\n",
    "    \"\"\"Configuration for sequence generation\"\"\"\n",
    "    target_kd: float  # Target KD in nM\n",
    "    target_tm1: float  # Target melting temperature 1\n",
    "    target_poi: float  # Target % POI\n",
    "\n",
    "    # Generation parameters\n",
    "    population_size: int = 10\n",
    "    num_iterations: int = 10\n",
    "    mutation_rate: float = 0.1\n",
    "    crossover_rate: float = 0.8\n",
    "\n",
    "    # Sequence constraints\n",
    "    min_length_vh: int = 110\n",
    "    max_length_vh: int = 130\n",
    "    min_length_vl: int = 105\n",
    "    max_length_vl: int = 125\n",
    "\n",
    "    # Template sequences \n",
    "    vh_template: str = \"EVQLVESGGGLVQPGGSLRLSCAASGFTFSSYAMSWVRQAPGKGLEWVSAINTKGLTNYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCAKGWFDYWGQGTLVTVSS\" \n",
    "    vl_template: str = \"DIQMTQSPSSLSASVGDRVTITCRASQGISNYLNWYQQKPGKAPKLLIYYASNLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYSTPYTFGQGTKVEIK\"   \n",
    "\n",
    "class AntibodyGenerator:\n",
    "    def __init__(self,\n",
    "                 model: nn.Module,\n",
    "                 config: GenerationConfig,\n",
    "                 exp_scaler):\n",
    "        \"\"\"\n",
    "        Initialize generator with trained model\n",
    "\n",
    "        Args:\n",
    "            model: Trained AntibodyPropertyPredictor\n",
    "            config: Generation configuration\n",
    "            exp_scaler: StandardScaler for experimental features\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.exp_scaler = exp_scaler\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        # Amino acid vocabulary\n",
    "        self.aa_vocab = {aa: idx for idx, aa in enumerate('ACDEFGHIKLMNPQRSTVWY')}\n",
    "        self.idx_to_aa = {idx: aa for aa, idx in self.aa_vocab.items()}\n",
    "\n",
    "        # Initialize CDR position cache\n",
    "        self.cdr_cache = {}\n",
    "\n",
    "    def _get_cdr_positions(self, sequence: str, chain_type: str) -> Set[int]:\n",
    "        \"\"\"\n",
    "        Use ANARCI to identify CDR positions in the sequence\n",
    "        \n",
    "        Args:\n",
    "            sequence: Amino acid sequence\n",
    "            chain_type: 'H' for heavy chain or 'L' for light chain\n",
    "        \n",
    "        Returns:\n",
    "            Set of positions (0-based indices) that are in CDRs\n",
    "        \"\"\"\n",
    "        # Check cache first\n",
    "        cache_key = (sequence, chain_type)\n",
    "        if cache_key in self.cdr_cache:\n",
    "            return self.cdr_cache[cache_key]\n",
    "\n",
    "        # Run ANARCI\n",
    "        numbering = run_anarci([('seq', sequence)], scheme='kabat', output=False)\n",
    "        \n",
    "        if not numbering or not numbering[0][0]:\n",
    "            logger.warning(f\"ANARCI failed to number {chain_type} chain sequence\")\n",
    "            return set()\n",
    "\n",
    "        # Extract CDR positions based on Kabat numbering\n",
    "        cdr_ranges = {\n",
    "            'H': [\n",
    "                (31, 35),   # CDR-H1\n",
    "                (50, 65),   # CDR-H2\n",
    "                (95, 102)   # CDR-H3\n",
    "            ],\n",
    "            'L': [\n",
    "                (24, 34),   # CDR-L1\n",
    "                (50, 56),   # CDR-L2\n",
    "                (89, 97)    # CDR-L3\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        numbering_map = numbering[1][0][0][0]  # Get numbering for first sequence\n",
    "        cdr_positions = set()\n",
    "        \n",
    "        for start, end in cdr_ranges[chain_type]:\n",
    "            for pos in range(len(sequence)):\n",
    "                if pos < len(numbering_map):\n",
    "                    num = numbering_map[pos][0][0]\n",
    "                    if start <= num <= end:\n",
    "                        cdr_positions.add(pos)\n",
    "\n",
    "        # Cache result\n",
    "        self.cdr_cache[cache_key] = cdr_positions\n",
    "        return cdr_positions\n",
    "\n",
    "    def _mutate_sequence(self, sequence: str, chain_type: str) -> str:\n",
    "        \"\"\"Apply random mutations only to CDR regions\"\"\"\n",
    "        cdr_positions = self._get_cdr_positions(sequence, chain_type)\n",
    "        \n",
    "        if not cdr_positions:\n",
    "            logger.warning(f\"No CDR positions identified for {chain_type} chain, skipping mutation\")\n",
    "            return sequence\n",
    "\n",
    "        sequence = list(sequence)\n",
    "        for pos in cdr_positions:\n",
    "            if random.random() < self.config.mutation_rate:\n",
    "                sequence[pos] = random.choice(list(self.aa_vocab.keys()))\n",
    "        return ''.join(sequence)\n",
    "\n",
    "    def _crossover(self, pair1: Tuple[str, str], pair2: Tuple[str, str]) -> Tuple[Tuple[str, str], Tuple[str, str]]:\n",
    "        \"\"\"Perform crossover between two antibody pairs, preserving framework regions\"\"\"\n",
    "        vh1, vl1 = pair1\n",
    "        vh2, vl2 = pair2\n",
    "\n",
    "        if random.random() < self.config.crossover_rate:\n",
    "            # Get CDR positions\n",
    "            vh1_cdrs = self._get_cdr_positions(vh1, 'H')\n",
    "            vh2_cdrs = self._get_cdr_positions(vh2, 'H')\n",
    "            vl1_cdrs = self._get_cdr_positions(vl1, 'L')\n",
    "            vl2_cdrs = self._get_cdr_positions(vl2, 'L')\n",
    "\n",
    "            # Create new sequences starting with templates\n",
    "            new_vh1 = list(vh1)\n",
    "            new_vh2 = list(vh2)\n",
    "            new_vl1 = list(vl1)\n",
    "            new_vl2 = list(vl2)\n",
    "\n",
    "            # Crossover VH CDRs\n",
    "            for pos in vh1_cdrs.union(vh2_cdrs):\n",
    "                if random.random() < 0.5:\n",
    "                    if pos < len(vh1) and pos < len(vh2):\n",
    "                        new_vh1[pos], new_vh2[pos] = vh2[pos], vh1[pos]\n",
    "\n",
    "            # Crossover VL CDRs\n",
    "            for pos in vl1_cdrs.union(vl2_cdrs):\n",
    "                if random.random() < 0.5:\n",
    "                    if pos < len(vl1) and pos < len(vl2):\n",
    "                        new_vl1[pos], new_vl2[pos] = vl2[pos], vl1[pos]\n",
    "\n",
    "            return (''.join(new_vh1), ''.join(new_vl1)), (''.join(new_vh2), ''.join(new_vl2))\n",
    "\n",
    "        return pair1, pair2\n",
    "\n",
    "    def _initialize_sequence(self, template: str, length: int, chain_type: str) -> str:\n",
    "        \"\"\"Generate sequence based on template, randomizing CDRs\"\"\"\n",
    "        # Start with template\n",
    "        sequence = list(template[:length])\n",
    "        \n",
    "        # Randomize CDR positions\n",
    "        cdr_positions = self._get_cdr_positions(template, chain_type)\n",
    "        for pos in cdr_positions:\n",
    "            if pos < length:\n",
    "                sequence[pos] = random.choice(list(self.aa_vocab.keys()))\n",
    "        \n",
    "        return ''.join(sequence)\n",
    "\n",
    "    def _initialize_population(self) -> List[Tuple[str, str]]:\n",
    "        \"\"\"Generate initial population of VH, VL pairs based on templates\"\"\"\n",
    "        population = []\n",
    "\n",
    "        for _ in range(self.config.population_size):\n",
    "            vh_length = random.randint(self.config.min_length_vh,\n",
    "                                     self.config.max_length_vh)\n",
    "            vl_length = random.randint(self.config.min_length_vl,\n",
    "                                     self.config.max_length_vl)\n",
    "\n",
    "            vh = self._initialize_sequence(self.config.vh_template, vh_length, 'H')\n",
    "            vl = self._initialize_sequence(self.config.vl_template, vl_length, 'L')\n",
    "\n",
    "            population.append((vh, vl))\n",
    "\n",
    "        return population\n",
    "\n",
    "    # Rest of the methods remain the same as in original implementation\n",
    "    def _sequence_to_tensor(self, sequence: str) -> torch.Tensor:\n",
    "        return torch.tensor([self.aa_vocab[aa] for aa in sequence],\n",
    "                          dtype=torch.long,\n",
    "                          device=self.device)\n",
    "\n",
    "    def _tensor_to_sequence(self, tensor: torch.Tensor) -> str:\n",
    "        return ''.join(self.idx_to_aa[idx.item()] for idx in tensor)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict_properties(self, vh_seq: str, vl_seq: str) -> Dict[str, float]:\n",
    "        vh_tensor = self._sequence_to_tensor(vh_seq)\n",
    "        vl_tensor = self._sequence_to_tensor(vl_seq)\n",
    "        concat = torch.transpose(pad_sequence([vh_tensor, vl_tensor]),0,1).unsqueeze(0)\n",
    "        \n",
    "        output = self.model(concat)\n",
    "        scaled_output = self.exp_scaler.inverse_transform(output.cpu().numpy())\n",
    "        return {\n",
    "            'KD': scaled_output[0][0],\n",
    "            'Tm1': scaled_output[0][1],\n",
    "            'POI': scaled_output[0][2]\n",
    "        }\n",
    "\n",
    "    def _fitness_function(self, vh: str, vl: str) -> float:\n",
    "        props = self.predict_properties(vh, vl)\n",
    "        kd_error = abs(props['KD'] - self.config.target_kd) / self.config.target_kd\n",
    "        tm1_error = abs(props['Tm1'] - self.config.target_tm1) / self.config.target_tm1\n",
    "        poi_error = abs(props['POI'] - self.config.target_poi) / self.config.target_poi\n",
    "        total_error = (kd_error * 0.4 + tm1_error * 0.3 + poi_error * 0.3)\n",
    "        return 1.0 / (1.0 + total_error)\n",
    "\n",
    "    def generate_sequences(self) -> List[Dict]:\n",
    "        population = self._initialize_population()\n",
    "        best_fitness = 0\n",
    "        best_solution = None\n",
    "\n",
    "        for iteration in tqdm(range(self.config.num_iterations)):\n",
    "            fitness_scores = [\n",
    "                self._fitness_function(vh, vl)\n",
    "                for vh, vl in population\n",
    "            ]\n",
    "\n",
    "            max_fitness_idx = np.argmax(fitness_scores)\n",
    "            if fitness_scores[max_fitness_idx] > best_fitness:\n",
    "                best_fitness = fitness_scores[max_fitness_idx]\n",
    "                best_solution = population[max_fitness_idx]\n",
    "\n",
    "            selection_probs = np.array(fitness_scores) / sum(fitness_scores)\n",
    "            selection_probs = np.nan_to_num(selection_probs, nan = 1/len(fitness_scores))\n",
    "            parent_indices = np.random.choice(\n",
    "                len(population),\n",
    "                size=len(population),\n",
    "                p=selection_probs\n",
    "            )\n",
    "            parents = [population[i] for i in parent_indices]\n",
    "\n",
    "            next_generation = []\n",
    "            for i in range(0, len(parents), 2):\n",
    "                if i + 1 < len(parents):\n",
    "                    child1, child2 = self._crossover(parents[i], parents[i+1])\n",
    "                    child1 = (self._mutate_sequence(child1[0], 'H'),\n",
    "                            self._mutate_sequence(child1[1], 'L'))\n",
    "                    child2 = (self._mutate_sequence(child2[0], 'H'),\n",
    "                            self._mutate_sequence(child2[1], 'L'))\n",
    "                    next_generation.extend([child1, child2])\n",
    "\n",
    "            population = next_generation\n",
    "            logger.info(f\"Iteration {iteration}, Best Fitness: {best_fitness:.4f}\")\n",
    "\n",
    "        results = []\n",
    "        for vh, vl in population:\n",
    "            properties = self.predict_properties(vh, vl)\n",
    "            fitness = self._fitness_function(vh, vl)\n",
    "            results.append({\n",
    "                'VH': vh,\n",
    "                'VL': vl,\n",
    "                'properties': properties,\n",
    "                'fitness': fitness\n",
    "            })\n",
    "\n",
    "        results.sort(key=lambda x: x['fitness'], reverse=True)\n",
    "        return results[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d457d2a8ddd0a7",
   "metadata": {},
   "source": [
    "# Using the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80da7ad628e85f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]INFO:__main__:Iteration 0, Best Fitness: 0.6955\n",
      " 10%|█         | 1/10 [00:01<00:15,  1.74s/it]INFO:__main__:Iteration 1, Best Fitness: 0.6955\n",
      " 20%|██        | 2/10 [00:02<00:10,  1.37s/it]INFO:__main__:Iteration 2, Best Fitness: 0.6955\n",
      " 30%|███       | 3/10 [00:04<00:10,  1.44s/it]INFO:__main__:Iteration 3, Best Fitness: 0.6955\n",
      " 40%|████      | 4/10 [00:05<00:07,  1.28s/it]INFO:__main__:Iteration 4, Best Fitness: 0.6955\n",
      " 50%|█████     | 5/10 [00:07<00:08,  1.70s/it]INFO:__main__:Iteration 5, Best Fitness: 0.6955\n",
      " 60%|██████    | 6/10 [00:10<00:07,  1.85s/it]INFO:__main__:Iteration 6, Best Fitness: 0.6955\n",
      " 70%|███████   | 7/10 [00:11<00:05,  1.70s/it]INFO:__main__:Iteration 7, Best Fitness: 0.6955\n",
      " 80%|████████  | 8/10 [00:13<00:03,  1.68s/it]INFO:__main__:Iteration 8, Best Fitness: 0.6955\n",
      " 90%|█████████ | 9/10 [00:14<00:01,  1.74s/it]INFO:__main__:Iteration 9, Best Fitness: 0.6955\n",
      "100%|██████████| 10/10 [00:16<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Candidate 1:\n",
      "VH: EVQLVESGGGLVQPGGSLRLSCAASGFTFSTQSDAWVRQAPGKGLEWVSGGLHWYLVRQHYRMQLEDTISRDNSKNTLYLQMNSLRAEDTAVYYCAKNKTNTTEKGVLVTVSS\n",
      "VL: DIQMTQSPSSLSASVGDRVTITCDSPRPHYNFTSWYQQKPGKAPKLLIYCQVHKPRGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCDCGHSQVKPFGQGTKVEIK\n",
      "Predicted properties:\n",
      "  KD: 0.00\n",
      "  Tm1: 68.49\n",
      "  POI: 98.77\n",
      "Fitness score: 0.6955\n",
      "\n",
      "Candidate 2:\n",
      "VH: EVQLVESGGGLVQPGGSLRLSCAASGFTFSAQSDLWVRQAPGKGLEWVSPCIHCAEVMQIFRMQNEFTISRDNSKNTLYLQMNSLRAEDTAVYYCAKNGTNCTINFVLVTVSS\n",
      "VL: DIQMTQSPSSLSASVGDRVTITCDAGREFYNVTIWYQQKPGKAPKLLIYQEEWKEGGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCDVGLMQCGNFGQGTKVEIK\n",
      "Predicted properties:\n",
      "  KD: 0.00\n",
      "  Tm1: 68.50\n",
      "  POI: 98.78\n",
      "Fitness score: 0.6955\n",
      "\n",
      "Candidate 3:\n",
      "VH: EVQLVESGGGLVQPGGSLRLSCAASGFTFSHCAFDWVRQAPGKGLEWVSPRSHMIEQCQIYIRQVPDTISRDNSKNTLYLQMNSLRAEDTAVYYCAKNEGQCCINGTLVTVSS\n",
      "VL: DIQMTQSPSSLSASVGDRVTITCFAPREARSLTSWYQQKPGKAPKLLIYCQVMGERGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCFHGEMEFNNFGQGTKVEIK\n",
      "Predicted properties:\n",
      "  KD: 0.00\n",
      "  Tm1: 68.49\n",
      "  POI: 98.77\n",
      "Fitness score: 0.6955\n",
      "\n",
      "Candidate 4:\n",
      "VH: EVQLVESGGGLVQPGGSLRLSCAASGFTFSDTSSNWVRQAPGKGLEWVSHGGVAKLAVAIYQFQYEDTISRDNSKNTLYLQMNSLRAEDTAVYYCAKNTTRGCFSFTLVTVSS\n",
      "VL: DIQMTQSPSSLSASVGDRVTITCDCPIEFCNFFSWYQQKPGKAPKLLIYCAPMKPHGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCFCGEEEQTVFGQGTKVEIK\n",
      "Predicted properties:\n",
      "  KD: 0.00\n",
      "  Tm1: 68.49\n",
      "  POI: 98.77\n",
      "Fitness score: 0.6955\n",
      "\n",
      "Candidate 5:\n",
      "VH: EVQLVESGGGLVQPGGSLRLSCAASGFTFSMKSHLWVRQAPGKGLEWVSPRIVPALDTAIYQMINAFTISRDNSKNTLYLQMNSLRAEDTAVYYCAKNTTNCCFSFPLVTVSS\n",
      "VL: DIQMTQSPSSLSASVGDRVTITCDSPNEFCNLTVWYQQKPGKAPKLLIYQEVCKPGGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCFHGLDEFNNFGQGTKVEIK\n",
      "Predicted properties:\n",
      "  KD: 0.00\n",
      "  Tm1: 68.49\n",
      "  POI: 98.78\n",
      "Fitness score: 0.6955\n",
      "\n",
      "Candidate 6:\n",
      "VH: EVQLVESGGGLVQPGGSLRLSCAASGFTFSPYSSLWVRQAPGKGLEWVSHEGHVHLAYQAYLPTVRFTISRDNSKNTLYLQMNSLRAEDTAVYYCAKNYGICCFCNTLVTVSS\n",
      "VL: DIQMTQSPSSLSASVGDRVTITCDEYCIHDFDFIWYQQKPGKAPKLLIYCIVTSDRGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCYTGHMEFTRFGQGTKVEIK\n",
      "Predicted properties:\n",
      "  KD: 0.00\n",
      "  Tm1: 68.49\n",
      "  POI: 98.77\n",
      "Fitness score: 0.6955\n",
      "\n",
      "Candidate 7:\n",
      "VH: EVQLVESGGGLVQPGGSLRLSCAASGFTFSAWSSDWVRQAPGKGLEWVSPCLHCILVMQTFQMQNPDTISRDNSKNTLYLQMNSLRAEDTAVYYCAKNKTNVCISGTLVTVSS\n",
      "VL: DIQMTQSPSSLSASVGDRVTITCDSPIECPIPFSWYQQKPGKAPKLLIYCQNGTWCGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCFVGLSQFTNFGQGTKVEIK\n",
      "Predicted properties:\n",
      "  KD: 0.00\n",
      "  Tm1: 68.49\n",
      "  POI: 98.78\n",
      "Fitness score: 0.6955\n",
      "\n",
      "Candidate 8:\n",
      "VH: EVQLVESGGGLVQPGGSLRLSCAASGFTFSVWFGIWVRQAPGKGLEWVSPWGHMLLQSIIYVMFMAFTISRDNSKNTLYLQMNSLRAEDTAVYYCAKNEQNECESGPLVTVSS\n",
      "VL: DIQMTQSPSSLSASVGDRVTITCEERCMFAYDAVWYQQKPGKAPKLLIYIQVIKSYGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCFCGCHECTNFGQGTKVEIK\n",
      "Predicted properties:\n",
      "  KD: 0.00\n",
      "  Tm1: 68.50\n",
      "  POI: 98.79\n",
      "Fitness score: 0.6954\n",
      "\n",
      "Candidate 9:\n",
      "VH: EVQLVESGGGLVQPGGSLRLSCAASGFTFSHKSCAWVRQAPGKGLEWVSPRLHWILDSQKYIRILPDTISRDNSKNTLYLQMNSLRAEDTAVYYCAKNKTNCCESGTLVTVSS\n",
      "VL: DIQMTQSPSSLSASVGDRVTITCFAPIEFRILTPWYQQKPGKAPKLLIYCQVMGPKGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCFHGHSEFNPFGQGTKVEIK\n",
      "Predicted properties:\n",
      "  KD: 0.00\n",
      "  Tm1: 68.49\n",
      "  POI: 98.79\n",
      "Fitness score: 0.6954\n",
      "\n",
      "Candidate 10:\n",
      "VH: EVQLVESGGGLVQPGGSLRLSCAASGFTFSMQSDAWVRQAPGKGLEWVSPCLACILVMQKFRMQLEDTISRDNSKNTLYLQMNSLRAEDTAVYYCAKNKTNCTESGVLVTVSS\n",
      "VL: DIQMTQSPSSLSASVGDRVTITCDSPIEFYIPTSWYQQKPGKAPKLLIYCQVHKPRGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCDVGESQFNPFGQGTKVEIK\n",
      "Predicted properties:\n",
      "  KD: 0.00\n",
      "  Tm1: 68.50\n",
      "  POI: 98.80\n",
      "Fitness score: 0.6954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load the trained model and scaler\n",
    "model = AntibodyTransformer()\n",
    "model.load_state_dict(torch.load('best_model.pth', weights_only=True))\n",
    "exp_scaler = StandardScaler()\n",
    "\n",
    "df = pd.read_csv('../data/merged_antibody_data.csv')\n",
    "exp_scaler.fit(df[['binding_affinity_kd', 'thermostability_tm1_celsius', 'asec_monomerpct']])\n",
    "\n",
    "# Configure generation parameters\n",
    "config = GenerationConfig(\n",
    "    target_kd=1.0,    # Your target KD\n",
    "    target_tm1=75.0,  # Target melting temp 1\n",
    "    target_poi=95.0   # Target % POI\n",
    ")\n",
    "\n",
    "# Initialize and run generator\n",
    "generator = AntibodyGenerator(model, config, exp_scaler)\n",
    "candidates = generator.generate_sequences()\n",
    "\n",
    "# Print results\n",
    "for i, result in enumerate(candidates, 1):\n",
    "        print(f\"\\nCandidate {i}:\")\n",
    "        print(f\"VH: {result['VH']}\")\n",
    "        print(f\"VL: {result['VL']}\")\n",
    "        print(\"Predicted properties:\")\n",
    "        for prop, value in result['properties'].items():\n",
    "            print(f\"  {prop}: {value:.2f}\")\n",
    "        print(f\"Fitness score: {result['fitness']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

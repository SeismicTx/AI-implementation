{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "\n",
    "class AntibodyDataProcessor:\n",
    "    def __init__(self, data_dir):\n",
    "        \"\"\"\n",
    "        Initialize the data processor with the directory containing CSV files.\n",
    "\n",
    "        Args:\n",
    "            data_dir (str): Path to directory containing the CSV files\n",
    "        \"\"\"\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.datasets = {}\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Load all CSV files from the data directory.\"\"\"\n",
    "        for file_path in self.data_dir.glob('*.csv'):\n",
    "            name = file_path.stem\n",
    "            self.datasets[name] = pd.read_csv(file_path)\n",
    "\n",
    "    def _standardize_column_names(self, df, prefix=''):\n",
    "        \"\"\"\n",
    "        Standardize column names by removing special characters and units,\n",
    "        and adding prefixes to avoid column name conflicts.\n",
    "        \"\"\"\n",
    "\n",
    "        def clean_name(col):\n",
    "            if col != 'antibody_id':\n",
    "                # Remove units in parentheses or after _\n",
    "                col = re.sub(r'\\([^)]*\\)', '', col)\n",
    "                col = re.sub(r'_[^_]*/', '_', col)\n",
    "                # Remove special characters and standardize separators\n",
    "                col = re.sub(r'[^a-zA-Z0-9_]', '_', col)\n",
    "                # Remove duplicate underscores\n",
    "                col = re.sub(r'_+', '_', col)\n",
    "                # Remove trailing underscores\n",
    "                col = col.strip('_').lower()\n",
    "                return f\"{prefix}{col}\" if prefix else col\n",
    "            else:\n",
    "                return col\n",
    "\n",
    "        return df.rename(columns=lambda x: clean_name(x))\n",
    "\n",
    "    def _convert_to_numeric(self, df):\n",
    "        \"\"\"Convert string columns to numeric where possible.\"\"\"\n",
    "        for col in df.columns:\n",
    "            # Skip clearly non-numeric columns\n",
    "            if col in ['notes', 'comments', 'analyst', 'process', 'method', 'appearance', 'storage',\n",
    "                       'format', 'species', 'isotype', 'cell_line', 'batch', 'buffer', 'test_method']:\n",
    "                continue\n",
    "\n",
    "            if df[col].dtype == 'object':\n",
    "                # Try converting to numeric, handling percentage signs\n",
    "                try:\n",
    "                    df[col] = df[col].str.replace('%', '').astype(float)\n",
    "                except:\n",
    "                    pass\n",
    "        return df\n",
    "\n",
    "    def _handle_missing_values(self, df):\n",
    "        \"\"\"Handle missing values based on column type.\"\"\"\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        categorical_cols = df.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "        # For numeric columns, fill with median\n",
    "        df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "\n",
    "        # For categorical columns, fill with 'unknown'\n",
    "        df[categorical_cols] = df[categorical_cols].fillna('unknown')\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _standardize_antibody_ids(self):\n",
    "        \"\"\"Standardize antibody IDs across all datasets.\"\"\"\n",
    "        id_columns = {\n",
    "            'asec': 'ID',\n",
    "            'binding_affinity': 'Sample_ID',\n",
    "            'bioactivity': 'Sample_ID',\n",
    "            'charge_variants': 'SampleName',\n",
    "            'endotoxin': 'ID',\n",
    "            'expression_yields': 'Antibody_ID',\n",
    "            'glycan_profiling': 'Ab_ID',\n",
    "            'sequences': 'Antibody_ID',\n",
    "            'stability_timecourse': 'AntibodyName',\n",
    "            'thermostability': 'AntibodyID'\n",
    "        }\n",
    "\n",
    "        # Standardize ID column names\n",
    "        for dataset_name, id_col in id_columns.items():\n",
    "            if dataset_name in self.datasets:\n",
    "                self.datasets[dataset_name] = self.datasets[dataset_name].rename(\n",
    "                    columns={id_col: 'antibody_id'})\n",
    "\n",
    "    def process_datasets(self):\n",
    "        \"\"\"Process all datasets with standardization and cleaning steps.\"\"\"\n",
    "        # First standardize IDs\n",
    "        self._standardize_antibody_ids()\n",
    "\n",
    "        # Process each dataset\n",
    "        for name, df in self.datasets.items():\n",
    "            # Add prefix to avoid column name conflicts\n",
    "            df = self._standardize_column_names(df, prefix=f\"{name}_\")\n",
    "            # Convert string numbers to numeric\n",
    "            df = self._convert_to_numeric(df)\n",
    "            # Handle missing values\n",
    "            df = self._handle_missing_values(df)\n",
    "            # Update the processed dataset\n",
    "            self.datasets[name] = df\n",
    "\n",
    "    def merge_datasets(self):\n",
    "        \"\"\"\n",
    "        Merge all datasets on antibody_id.\n",
    "        Returns:\n",
    "            pd.DataFrame: Merged dataset\n",
    "        \"\"\"\n",
    "        # Start with sequences as base if available, otherwise use first available dataset\n",
    "        base_dataset = 'sequences'\n",
    "        if base_dataset not in self.datasets:\n",
    "            base_dataset = list(self.datasets.keys())[0]\n",
    "\n",
    "        merged_df = self.datasets[base_dataset]\n",
    "\n",
    "        # Merge rest of datasets\n",
    "        for name, df in self.datasets.items():\n",
    "            if name != base_dataset:\n",
    "                merged_df = merged_df.merge(df, on='antibody_id', how='outer')\n",
    "\n",
    "        return merged_df\n",
    "\n",
    "    def prepare_for_ml(self, merged_df):\n",
    "        \"\"\"\n",
    "        Prepare the merged dataset for machine learning.\n",
    "\n",
    "        Args:\n",
    "            merged_df (pd.DataFrame): Merged dataset\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: ML-ready dataset\n",
    "        \"\"\"\n",
    "        # Drop columns that aren't useful for ML\n",
    "        cols_to_drop = [col for col in merged_df.columns\n",
    "                        if any(x in col.lower() for x in ['notes', 'comments', 'analyst'])]\n",
    "        ml_df = merged_df.drop(columns=cols_to_drop)\n",
    "\n",
    "        # Convert categorical variables to dummy variables\n",
    "        categorical_columns = ml_df.select_dtypes(include=['object']).columns\n",
    "        ml_df = pd.get_dummies(ml_df, columns=categorical_columns)\n",
    "\n",
    "        # Final missing value handling\n",
    "        ml_df = ml_df.fillna(ml_df.median())\n",
    "\n",
    "        return ml_df\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Initialize processor\n",
    "    processor = AntibodyDataProcessor('../data')\n",
    "\n",
    "    # Load and process data\n",
    "    processor.load_data()\n",
    "    processor.process_datasets()\n",
    "\n",
    "    # Merge datasets\n",
    "    merged_df = processor.merge_datasets()\n",
    "\n",
    "    # Prepare for ML\n",
    "    ml_ready_df = processor.prepare_for_ml(merged_df)\n",
    "\n",
    "    # Save processed datasets\n",
    "    merged_df.to_csv('merged_antibody_data.csv', index=False)\n",
    "    ml_ready_df.to_csv('ml_ready_antibody_data.csv', index=False)\n",
    "\n",
    "    print(f\"Final dataset shape: {ml_ready_df.shape}\")\n",
    "    print(\"\\nFeature names:\")\n",
    "    print(ml_ready_df.columns.tolist())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

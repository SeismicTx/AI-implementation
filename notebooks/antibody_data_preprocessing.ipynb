{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b7ed19d-d668-4bd7-b8b7-4e4e388c6d87",
   "metadata": {},
   "source": [
    "# Define a class for loading, cleaning and merging antibody data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "\n",
    "class AntibodyDataProcessor:\n",
    "    def __init__(self, data_dir):\n",
    "        \"\"\"\n",
    "        Initialize the data processor with the directory containing CSV files.\n",
    "\n",
    "        Args:\n",
    "            data_dir (str): Path to directory containing the CSV files\n",
    "        \"\"\"\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.datasets = {}\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Load all CSV files from the data directory.\"\"\"\n",
    "        for file_path in self.data_dir.glob('*.csv'):\n",
    "            name = file_path.stem\n",
    "            self.datasets[name] = pd.read_csv(file_path)\n",
    "\n",
    "    def _standardize_column_names(self, df, prefix=''):\n",
    "        \"\"\"\n",
    "        Standardize column names by removing special characters and units,\n",
    "        and adding prefixes to avoid column name conflicts.\n",
    "        \"\"\"\n",
    "\n",
    "        def clean_name(col):\n",
    "            if col != 'antibody_id':\n",
    "                # Remove units in parentheses or after _\n",
    "                col = re.sub(r'\\([^)]*\\)', '', col)\n",
    "                col = re.sub(r'_[^_]*/', '_', col)\n",
    "                # Remove special characters and standardize separators\n",
    "                col = re.sub(r'[^a-zA-Z0-9_]', '_', col)\n",
    "                # Remove duplicate underscores\n",
    "                col = re.sub(r'_+', '_', col)\n",
    "                # Remove trailing underscores\n",
    "                col = col.strip('_').lower()\n",
    "                return f\"{prefix}{col}\" if prefix else col\n",
    "            else:\n",
    "                return col\n",
    "\n",
    "        return df.rename(columns=lambda x: clean_name(x))\n",
    "\n",
    "    def _convert_to_numeric(self, df):\n",
    "        \"\"\"Convert string columns to numeric where possible.\"\"\"\n",
    "        for col in df.columns:\n",
    "            # Skip clearly non-numeric columns\n",
    "            if col in ['notes', 'comments', 'analyst', 'process', 'method', 'appearance', 'storage',\n",
    "                       'format', 'species', 'isotype', 'cell_line', 'batch', 'buffer', 'test_method']:\n",
    "                continue\n",
    "\n",
    "            if df[col].dtype == 'object':\n",
    "                # Try converting to numeric, handling percentage signs\n",
    "                try:\n",
    "                    df[col] = df[col].str.replace('%', '').astype(float)\n",
    "                except:\n",
    "                    pass\n",
    "        return df\n",
    "\n",
    "    def _handle_missing_values(self, df):\n",
    "        \"\"\"Handle missing values based on column type.\"\"\"\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        categorical_cols = df.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "        # For numeric columns, fill with median\n",
    "        df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "\n",
    "        # For categorical columns, fill with 'unknown'\n",
    "        df[categorical_cols] = df[categorical_cols].fillna('unknown')\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _standardize_antibody_ids(self):\n",
    "        \"\"\"Standardize antibody IDs across all datasets.\"\"\"\n",
    "        id_columns = {\n",
    "            'asec': 'ID',\n",
    "            'binding_affinity': 'Sample_ID',\n",
    "            'bioactivity': 'Sample_ID',\n",
    "            'charge_variants': 'SampleName',\n",
    "            'endotoxin': 'ID',\n",
    "            'expression_yields': 'Antibody_ID',\n",
    "            'glycan_profiling': 'Ab_ID',\n",
    "            'sequences': 'Antibody_ID',\n",
    "            'stability_timecourse': 'AntibodyName',\n",
    "            'thermostability': 'AntibodyID'\n",
    "        }\n",
    "\n",
    "        # Standardize ID column names\n",
    "        for dataset_name, id_col in id_columns.items():\n",
    "            if dataset_name in self.datasets:\n",
    "                self.datasets[dataset_name] = self.datasets[dataset_name].rename(\n",
    "                    columns={id_col: 'antibody_id'})\n",
    "\n",
    "    def process_datasets(self):\n",
    "        \"\"\"Process all datasets with standardization and cleaning steps.\"\"\"\n",
    "        # First standardize IDs\n",
    "        self._standardize_antibody_ids()\n",
    "\n",
    "        # Process each dataset\n",
    "        for name, df in self.datasets.items():\n",
    "            # Add prefix to avoid column name conflicts\n",
    "            df = self._standardize_column_names(df, prefix=f\"{name}_\")\n",
    "            # Convert string numbers to numeric\n",
    "            df = self._convert_to_numeric(df)\n",
    "            # Handle missing values\n",
    "            df = self._handle_missing_values(df)\n",
    "            # Update the processed dataset\n",
    "            self.datasets[name] = df\n",
    "\n",
    "    def merge_datasets(self):\n",
    "        \"\"\"\n",
    "        Merge all datasets on antibody_id.\n",
    "        Returns:\n",
    "            pd.DataFrame: Merged dataset\n",
    "        \"\"\"\n",
    "        # Start with sequences as base if available, otherwise use first available dataset\n",
    "        base_dataset = 'sequences'\n",
    "        if base_dataset not in self.datasets:\n",
    "            base_dataset = list(self.datasets.keys())[0]\n",
    "\n",
    "        merged_df = self.datasets[base_dataset]\n",
    "\n",
    "        # Merge rest of datasets\n",
    "        for name, df in self.datasets.items():\n",
    "            if name != base_dataset:\n",
    "                merged_df = merged_df.merge(df, on='antibody_id', how='outer')\n",
    "\n",
    "        return merged_df\n",
    "\n",
    "    def prepare_for_ml(self, merged_df):\n",
    "        \"\"\"\n",
    "        Prepare the merged dataset for machine learning.\n",
    "\n",
    "        Args:\n",
    "            merged_df (pd.DataFrame): Merged dataset\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: ML-ready dataset\n",
    "        \"\"\"\n",
    "        # Drop columns that aren't useful for ML\n",
    "        cols_to_drop = [col for col in merged_df.columns\n",
    "                        if any(x in col.lower() for x in ['notes', 'comments', 'analyst'])]\n",
    "        ml_df = merged_df.drop(columns=cols_to_drop)\n",
    "\n",
    "        # Convert categorical variables to dummy variables\n",
    "        categorical_columns = ml_df.select_dtypes(include=['object']).columns\n",
    "        ml_df = pd.get_dummies(ml_df, columns=categorical_columns)\n",
    "\n",
    "        # Final missing value handling\n",
    "        ml_df = ml_df.fillna(ml_df.median())\n",
    "\n",
    "        return ml_df\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Initialize processor\n",
    "    processor = AntibodyDataProcessor('../data')\n",
    "\n",
    "    # Load and process data\n",
    "    processor.load_data()\n",
    "    processor.process_datasets()\n",
    "\n",
    "    # Merge datasets\n",
    "    merged_df = processor.merge_datasets()\n",
    "\n",
    "    # Prepare for ML\n",
    "    ml_ready_df = processor.prepare_for_ml(merged_df)\n",
    "\n",
    "    # Save processed datasets\n",
    "    merged_df.to_csv('../data/merged_antibody_data.csv', index=False)\n",
    "    ml_ready_df.to_csv('../data/ml_ready_antibody_data.csv', index=False)\n",
    "\n",
    "    print(f\"Final dataset shape: {ml_ready_df.shape}\")\n",
    "    print(\"\\nFeature names:\")\n",
    "    print(ml_ready_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e97ac1f9-da90-4f58-9b7e-efba2c639698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (5, 73)\n",
      "\n",
      "Feature names:\n",
      "['asec_monomerpct', 'asec_aggregates', 'asec_fragments_pct', 'asec_retentiontime', 'binding_affinity_kd_nm', 'binding_affinity_ka', 'binding_affinity_kd', 'binding_affinity_rmax', 'binding_affinity_chi2', 'binding_affinity_temperature_c', 'bioactivity_ec50_ml', 'bioactivity_max_response', 'bioactivity_hill_slope', 'bioactivity_r2', 'charge_variants_main_peak', 'charge_variants_acidic_variants', 'charge_variants_basic_variants', 'charge_variants_pi', 'endotoxin_sample_conc_ml', 'expression_yields_titer_l', 'expression_yields_viability_pct', 'expression_yields_culture_days', 'glycan_profiling_g0f', 'glycan_profiling_g1f', 'glycan_profiling_g2f', 'glycan_profiling_man5', 'glycan_profiling_other', 'stability_timecourse_timepoint_months', 'stability_timecourse_temp_c', 'stability_timecourse_monomer', 'stability_timecourse_potency_initial', 'stability_timecourse_ph', 'thermostability_tm1_celsius', 'thermostability_tm2_c', 'thermostability_tagg', 'thermostability_dg', 'antibody_id_MAB001', 'antibody_id_MAB002', 'antibody_id_MAB003', 'antibody_id_MAB004', 'antibody_id_MAB005', 'sequences_hc_sequence_EVQLVESGGGLVQPGGSLRLSCAASGFTFDDYAMHWVRQAPGKGLEWVSGISWNSGSIGYADSVKGRFTISRDNAKNSLYLQMNSLRAEDTAVYYCAKGPFDYWGQGTLVTVSS', 'sequences_hc_sequence_EVQLVESGGGLVQPGGSLRLSCAASGFTFSSYAMSWVRQAPGKGLEWVSAINTKGLTNYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCAKGWFDYWGQGTLVTVSS', 'sequences_hc_sequence_EVQLVESGGGLVQPGGSLRLSCAASGFTFSSYAMSWVRQAPGKGLEWVSAINTKGLTNYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCARGWFDYWGQGTLVTVSS', 'sequences_hc_sequence_EVQLVESGGGLVQPGGSLRLSCAASGFTFSSYAMSWVRQAPGKGLEWVSGINTKTLTNYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCAKDRFDYWGQGTLVTVSS', 'sequences_hc_sequence_EVQLVESGGGLVQPGGSLRLSCAASGFTFSSYWMSWVRQAPGKGLEWVANIKQDGSEKYYVDSVKGRFTISRDNAKNSLYLQMNSLRAEDTAVYYCARDGMDYWGQGTLVTVSS', 'sequences_lc_sequence_DIQMTQSPSSLSASVGDRVTITCRASQGIRNNLNWYQQKPGKAPKLLIYAASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYTTPYTFGQGTKVEIK', 'sequences_lc_sequence_DIQMTQSPSSLSASVGDRVTITCRASQGISNWLAWYQQKPGKAPKLLIYYASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQANSFPLTFGGGTKVEIK', 'sequences_lc_sequence_DIQMTQSPSSLSASVGDRVTITCRASQGISNYLNWYQQKPGKAPKLLIYYASNLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYSTPYTFGQGTKVEIK', 'sequences_lc_sequence_DIQMTQSPSSLSASVGDRVTITCRASQSISSYLNWYQQKPGKAPKLLIYYASNLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYSTPYTFGQGTKVEIK', 'sequences_lc_sequence_DIQMTQSPSSLSASVGDRVTITCRASQSISSYLNWYQQKPGKAPKLLIYYASSLQSGVPSRFSGSGSGTDFTLTISSLQPEDFATYYCQQSYSTPRTFGQGTKVEIK', 'sequences_format_IgG1', 'sequences_species_Human', 'sequences_isotype_kappa', 'binding_affinity_target_CD19', 'bioactivity_assay_date_2024-12-15', 'bioactivity_assay_date_2024-12-16', 'charge_variants_method_icIEF', 'endotoxin_endotoxin_mg_0.08', 'endotoxin_endotoxin_mg_0.15', 'endotoxin_endotoxin_mg_<0.1', 'endotoxin_endotoxin_mg_>1.0', 'endotoxin_test_method_LAL', 'endotoxin_dilution_1:10', 'endotoxin_result_FAIL', 'endotoxin_result_PASS', 'expression_yields_cell_line_CHO-K1', 'glycan_profiling_batch_B001', 'glycan_profiling_batch_B002', 'glycan_profiling_batch_B003', 'stability_timecourse_appearance_Clear', 'stability_timecourse_storage_2-8°C', 'stability_timecourse_storage_RT']\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

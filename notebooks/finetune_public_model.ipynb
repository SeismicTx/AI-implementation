{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1166be3-ec36-4eb9-b6d6-0f42db4d3f7f",
   "metadata": {},
   "source": [
    "# Fine-tuning ESM for antibody property prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efae73d5-ea7f-48f3-bedf-9ea92350b598",
   "metadata": {},
   "source": [
    "Instead of the simple direct encoding of amino acids we used initially, here we will leverage a pre-trained protein language model to tokenize the residues. We expect this to give better results the simple vocabulary-based approach, since the embeddings capture meaningful biological and chemical context of the amino acid sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66f5066f-6409-4c04-9467-15d405d9587d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fair-esm\n",
      "  Using cached fair_esm-2.0.0-py3-none-any.whl.metadata (37 kB)\n",
      "Using cached fair_esm-2.0.0-py3-none-any.whl (93 kB)\n",
      "Installing collected packages: fair-esm\n",
      "Successfully installed fair-esm-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install fair-esm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e9fa261-5316-4c34-9a29-a2880319f479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import esm\n",
    "from typing import List, Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ESMAntibodyDataset(Dataset):\n",
    "    def __init__(self, merged_experimental_df: str):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            merged_experimental_df: Path to CSV with columns for VH/VL sequences and experimental data\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(merged_experimental_df)\n",
    "        \n",
    "        # Load ESM-2 model and tokenizer\n",
    "        # We'll use the smallest ESM model (8M parameters) for performance, \n",
    "        # but for best results the larger versions should be used\n",
    "        self.model, self.alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
    "        self.batch_converter = self.alphabet.get_batch_converter()\n",
    "        self.model.eval()  # Set to eval mode since we're only using for embeddings\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        \n",
    "        # Prepare sequences for ESM\n",
    "        vh_data = [(\"vh\", row['sequences_hc_sequence'])]\n",
    "        vl_data = [(\"vl\", row['sequences_lc_sequence'])]\n",
    "        \n",
    "        # Get embeddings for VH and VL\n",
    "        with torch.no_grad():\n",
    "            # Process VH\n",
    "            _, _, vh_tokens = self.batch_converter(vh_data)\n",
    "            vh_results = self.model(vh_tokens, repr_layers=[6])\n",
    "            vh_embeddings = vh_results[\"representations\"][6]  # Use last layer\n",
    "            \n",
    "            # Process VL\n",
    "            _, _, vl_tokens = self.batch_converter(vl_data)\n",
    "            vl_results = self.model(vl_tokens, repr_layers=[6])\n",
    "            vl_embeddings = vl_results[\"representations\"][6]\n",
    "        \n",
    "        # Extract target variables\n",
    "        targets = torch.tensor([\n",
    "            row['binding_affinity_kd'],\n",
    "            row['thermostability_tm1_celsius'],\n",
    "            row['asec_monomerpct']\n",
    "        ], dtype=torch.float)\n",
    "        \n",
    "        return (vh_embeddings, vl_embeddings), targets\n",
    "\n",
    "class ESMAntibodyTransformer(nn.Module):\n",
    "    def __init__(self, esm_dim=320, d_model=256, nhead=8, num_layers=3, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            esm_dim: Dimension of ESM embeddings (320 for ESM-2 8M)\n",
    "            d_model: Internal transformer dimension\n",
    "            nhead: Number of attention heads\n",
    "            num_layers: Number of transformer layers\n",
    "            dropout: Dropout rate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Project ESM embeddings to transformer dimension\n",
    "        self.vh_projection = nn.Linear(esm_dim, d_model)\n",
    "        self.vl_projection = nn.Linear(esm_dim, d_model)\n",
    "        \n",
    "        # Transformer encoder layer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=1024,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Transformer encoder\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            encoder_layer=encoder_layer,\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        \n",
    "        # Output layers\n",
    "        self.fc1 = nn.Linear(d_model * 2, 256)  # *2 because we concatenate VH and VL\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 3)  # 3 outputs: KD, Tm1, POI\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        vh_embed, vl_embed = x\n",
    "        \n",
    "        # Project ESM embeddings\n",
    "        vh = self.vh_projection(vh_embed.squeeze(0))\n",
    "        vl = self.vl_projection(vl_embed.squeeze(0))\n",
    "        \n",
    "        # Pass through transformer\n",
    "        vh_encoded = self.transformer(vh)\n",
    "        vl_encoded = self.transformer(vl)\n",
    "        \n",
    "        # Pool sequence dimension using attention-weighted mean\n",
    "        vh_pooled = vh_encoded.mean(dim=1)  # [batch_size, d_model]\n",
    "        vl_pooled = vl_encoded.mean(dim=1)  # [batch_size, d_model]\n",
    "        \n",
    "        # Concatenate VH and VL features\n",
    "        combined = torch.cat([vh_pooled, vl_pooled], dim=1)\n",
    "        \n",
    "        # Final MLP layers\n",
    "        x = F.relu(self.fc1(combined))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    num_epochs: int = 10,\n",
    "    learning_rate: float = 1e-4,\n",
    "    device: str = 'cuda'\n",
    "):\n",
    "    \"\"\"Training loop with validation\"\"\"\n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "    )\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for (vh_embed, vl_embed), targets in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\"):\n",
    "            vh_embed = vh_embed.to(device)\n",
    "            vl_embed = vl_embed.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model((vh_embed, vl_embed))\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for (vh_embed, vl_embed), targets in tqdm(val_loader, desc=f\"Epoch {epoch+1} Validation\"):\n",
    "                vh_embed = vh_embed.to(device)\n",
    "                vl_embed = vl_embed.to(device)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                outputs = model((vh_embed, vl_embed))\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print(f'Training Loss: {train_loss:.4f}')\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_esm_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db19840d-d4dc-4343-aa65-3df1be450f93",
   "metadata": {},
   "source": [
    "While we can construct a training procedure in a similar fashion to the transformer based on simple indexing of amino acids, it probably won't work on a basic SageMaker instance due to the size of the ESM model. For a more advanced example of fine-tuning ESM-2 using the full capabilities of SageMaker, see https://github.com/aws-samples/aws-healthcare-lifescience-ai-ml-sample-notebooks/blob/main/workshops/Protein_Language_Modelling/finetune_esm_on_oas/Fine-Tune-ESM2-On-OAS-Paired.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb70207b-ffc6-43d1-be94-a2f65f25885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Create dataset\n",
    "    dataset = ESMAntibodyDataset('../data/merged_antibody_data.csv')\n",
    "\n",
    "    # Split dataset\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        dataset, [train_size, val_size]\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = ESMAntibodyTransformer()\n",
    "    \n",
    "    # Train model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        num_epochs=10,\n",
    "        learning_rate=1e-4,\n",
    "        device=device\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea1730d3-a82a-4128-b9b9-e89ce58a5745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch 1 Training: 100%|██████████| 4/4 [00:00<00:00,  4.21it/s]\n",
      "Epoch 1 Validation: 100%|██████████| 1/1 [00:00<00:00,  9.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Training Loss: 4765.7161\n",
      "Validation Loss: 4776.3813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|██████████| 4/4 [00:00<00:00,  5.37it/s]\n",
      "Epoch 2 Validation: 100%|██████████| 1/1 [00:00<00:00,  9.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "Training Loss: 4728.6019\n",
      "Validation Loss: 4741.2944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|██████████| 4/4 [00:00<00:00,  5.39it/s]\n",
      "Epoch 3 Validation: 100%|██████████| 1/1 [00:00<00:00,  9.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "Training Loss: 4689.8719\n",
      "Validation Loss: 4708.2534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|██████████| 4/4 [00:00<00:00,  5.47it/s]\n",
      "Epoch 4 Validation: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "Training Loss: 4669.8660\n",
      "Validation Loss: 4676.2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|██████████| 4/4 [00:00<00:00,  5.15it/s]\n",
      "Epoch 5 Validation: 100%|██████████| 1/1 [00:00<00:00, 10.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "Training Loss: 4616.8071\n",
      "Validation Loss: 4642.6641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 100%|██████████| 4/4 [00:00<00:00,  5.95it/s]\n",
      "Epoch 6 Validation: 100%|██████████| 1/1 [00:00<00:00,  7.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "Training Loss: 4603.6351\n",
      "Validation Loss: 4608.0366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training: 100%|██████████| 4/4 [00:01<00:00,  3.47it/s]\n",
      "Epoch 7 Validation: 100%|██████████| 1/1 [00:00<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "Training Loss: 4560.8043\n",
      "Validation Loss: 4572.7319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training: 100%|██████████| 4/4 [00:01<00:00,  3.48it/s]\n",
      "Epoch 8 Validation: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "Training Loss: 4507.8838\n",
      "Validation Loss: 4533.6333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Training: 100%|██████████| 4/4 [00:01<00:00,  3.91it/s]\n",
      "Epoch 9 Validation: 100%|██████████| 1/1 [00:00<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "Training Loss: 4466.9601\n",
      "Validation Loss: 4491.2637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Training: 100%|██████████| 4/4 [00:01<00:00,  3.67it/s]\n",
      "Epoch 10 Validation: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "Training Loss: 4441.6740\n",
      "Validation Loss: 4444.6763\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

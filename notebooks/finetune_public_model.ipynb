{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1166be3-ec36-4eb9-b6d6-0f42db4d3f7f",
   "metadata": {},
   "source": [
    "# Fine-tuning ESM for antibody property prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66f5066f-6409-4c04-9467-15d405d9587d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fair-esm\n",
      "  Downloading fair_esm-2.0.0-py3-none-any.whl.metadata (37 kB)\n",
      "Downloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n",
      "Installing collected packages: fair-esm\n",
      "Successfully installed fair-esm-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install fair-esm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e9fa261-5316-4c34-9a29-a2880319f479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import esm\n",
    "from typing import List, Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ESMAntibodyDataset(Dataset):\n",
    "    def __init__(self, merged_experimental_df: str):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            merged_experimental_df: Path to CSV with columns for VH/VL sequences and experimental data\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(merged_experimental_df)\n",
    "        \n",
    "        # Load ESM-2 model and tokenizer\n",
    "        self.model, self.alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "        self.batch_converter = self.alphabet.get_batch_converter()\n",
    "        self.model.eval()  # Set to eval mode since we're only using for embeddings\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        \n",
    "        # Prepare sequences for ESM\n",
    "        vh_data = [(\"vh\", row['sequences_hc_sequence'])]\n",
    "        vl_data = [(\"vl\", row['sequences_lc_sequence'])]\n",
    "        \n",
    "        # Get embeddings for VH and VL\n",
    "        with torch.no_grad():\n",
    "            # Process VH\n",
    "            _, _, vh_tokens = self.batch_converter(vh_data)\n",
    "            vh_results = self.model(vh_tokens, repr_layers=[33])\n",
    "            vh_embeddings = vh_results[\"representations\"][33]  # Use last layer\n",
    "            \n",
    "            # Process VL\n",
    "            _, _, vl_tokens = self.batch_converter(vl_data)\n",
    "            vl_results = self.model(vl_tokens, repr_layers=[33])\n",
    "            vl_embeddings = vl_results[\"representations\"][33]\n",
    "        \n",
    "        # Extract target variables\n",
    "        targets = torch.tensor([\n",
    "            row['binding_affinity_kd'],\n",
    "            row['thermostability_tm1_celsius'],\n",
    "            row['asec_monomerpct']\n",
    "        ], dtype=torch.float)\n",
    "        \n",
    "        return (vh_embeddings, vl_embeddings), targets\n",
    "\n",
    "class ESMAntibodyTransformer(nn.Module):\n",
    "    def __init__(self, esm_dim=1280, d_model=256, nhead=8, num_layers=3, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            esm_dim: Dimension of ESM embeddings (1280 for ESM-2)\n",
    "            d_model: Internal transformer dimension\n",
    "            nhead: Number of attention heads\n",
    "            num_layers: Number of transformer layers\n",
    "            dropout: Dropout rate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Project ESM embeddings to transformer dimension\n",
    "        self.vh_projection = nn.Linear(esm_dim, d_model)\n",
    "        self.vl_projection = nn.Linear(esm_dim, d_model)\n",
    "        \n",
    "        # Transformer encoder layer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=1024,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Transformer encoder\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            encoder_layer=encoder_layer,\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        \n",
    "        # Output layers\n",
    "        self.fc1 = nn.Linear(d_model * 2, 256)  # *2 because we concatenate VH and VL\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 3)  # 3 outputs: KD, Tm1, POI\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.double()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        vh_embed, vl_embed = x\n",
    "        \n",
    "        # Project ESM embeddings\n",
    "        vh = self.vh_projection(vh_embed)\n",
    "        vl = self.vl_projection(vl_embed)\n",
    "        \n",
    "        # Pass through transformer\n",
    "        vh_encoded = self.transformer(vh)\n",
    "        vl_encoded = self.transformer(vl)\n",
    "        \n",
    "        # Pool sequence dimension using attention-weighted mean\n",
    "        vh_pooled = vh_encoded.mean(dim=1)  # [batch_size, d_model]\n",
    "        vl_pooled = vl_encoded.mean(dim=1)  # [batch_size, d_model]\n",
    "        \n",
    "        # Concatenate VH and VL features\n",
    "        combined = torch.cat([vh_pooled, vl_pooled], dim=1)\n",
    "        \n",
    "        # Final MLP layers\n",
    "        x = F.relu(self.fc1(combined))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    num_epochs: int = 10,\n",
    "    learning_rate: float = 1e-4,\n",
    "    device: str = 'cuda'\n",
    "):\n",
    "    \"\"\"Training loop with validation\"\"\"\n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    scheduler = torch.optim.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "    )\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for (vh_embed, vl_embed), targets in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\"):\n",
    "            vh_embed = vh_embed.to(device)\n",
    "            vl_embed = vl_embed.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model((vh_embed, vl_embed))\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for (vh_embed, vl_embed), targets in tqdm(val_loader, desc=f\"Epoch {epoch+1} Validation\"):\n",
    "                vh_embed = vh_embed.to(device)\n",
    "                vl_embed = vl_embed.to(device)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                outputs = model((vh_embed, vl_embed))\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print(f'Training Loss: {train_loss:.4f}')\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_esm_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db19840d-d4dc-4343-aa65-3df1be450f93",
   "metadata": {},
   "source": [
    "While we can construct a training procedure in a similar fashion to the transformer based on simple indexing of amino acids, it probably won't work on a basic SageMaker instance due to the size of the ESM model. For a more advanced example of fine-tuning ESM-2 using the full capabilities of SageMaker, see https://github.com/aws-samples/aws-healthcare-lifescience-ai-ml-sample-notebooks/blob/main/workshops/Protein_Language_Modelling/finetune_esm_on_oas/Fine-Tune-ESM2-On-OAS-Paired.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb70207b-ffc6-43d1-be94-a2f65f25885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Create dataset\n",
    "    dataset = ESMAntibodyDataset('../data/merged_antibody_data.csv')\n",
    "\n",
    "    # Split dataset\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        dataset, [train_size, val_size]\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=32)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = ESMAntibodyTransformer()\n",
    "    \n",
    "    # Train model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        num_epochs=20,\n",
    "        learning_rate=1e-4,\n",
    "        device=device\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

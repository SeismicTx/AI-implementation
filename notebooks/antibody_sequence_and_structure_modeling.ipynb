{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "369bd0554bf1df4e",
   "metadata": {},
   "source": [
    "# Integrating structural modeling for antibody optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f3d77a-70a0-4494-906e-59c4ea46029f",
   "metadata": {},
   "source": [
    "We'll now incorporate structural constraints into the antibody design process, using the antibody structure prediction model ABodyBuilder2 from the ImmuneBuilder toolkit: https://github.com/oxpig/ImmuneBuilder.git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f728bb74-05b2-46c5-bc39-48b8fff7cb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda install -c conda-forge openmm pdbfixer\n",
    "%conda install -c bioconda anarci\n",
    "%pip install ImmuneBuilder\n",
    "%pip install fair-esm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "859a2c94-3e34-4b46-8653-9b3bdac09be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from dataclasses import dataclass\n",
    "from Bio.PDB import *\n",
    "from Bio.PDB.DSSP import dssp_dict_from_pdb_file\n",
    "import logging\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ImmuneBuilder import ABodyBuilder2\n",
    "from models.anarci_ab_generator import GenerationConfig, AntibodyGenerator\n",
    "from models.antibody_transformer import AntibodyTransformer\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class StructuralConstraints:\n",
    "    \"\"\"Structural constraints for antibody design\"\"\"\n",
    "    max_cdr_rmsd: float = 2.0  # Angstroms\n",
    "    min_cdr_exposure: float = 0.6  # Fraction exposed\n",
    "    max_aggregation_prone_regions: int = 2\n",
    "    min_stability_score: float = -3.0  # Rosetta energy units\n",
    "\n",
    "class StructurePredictor:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize structure prediction models\"\"\"\n",
    "        # Initialize ABodyBuilder2\n",
    "        self.abodybuilder = ABodyBuilder2()\n",
    "        \n",
    "        # Load additional structure scoring models\n",
    "        self.parser = PDBParser()\n",
    "        self.dssp = DSSP\n",
    "\n",
    "    def predict_structure(self, vh_seq: str, vl_seq: str) -> str:\n",
    "        \"\"\"Predict antibody structure using ABodyBuilder2\"\"\"\n",
    "        try:\n",
    "            sequences = {\n",
    "                'VH': vh_seq,\n",
    "                'VL': vl_seq\n",
    "            }\n",
    "            \n",
    "            # Predict structure using ABodyBuilder2\n",
    "            result = self.abodybuilder.predict_structure(\n",
    "                sequences,\n",
    "                output_format='pdb_string'  # Get PDB format as string\n",
    "            )\n",
    "            \n",
    "            return result['pdb_string']\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Structure prediction failed: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def calculate_structural_features(self, pdb_str: str) -> Dict:\n",
    "        \"\"\"Calculate structural features from PDB structure\"\"\"\n",
    "        # Create temporary PDB file\n",
    "        with open(\"temp.pdb\", \"w\") as f:\n",
    "            f.write(pdb_str)\n",
    "\n",
    "        # Parse structure\n",
    "        structure = self.parser.get_structure(\"temp\", \"temp.pdb\")\n",
    "\n",
    "        # Calculate features\n",
    "        dssp_dict = dssp_dict_from_pdb_file(\"temp.pdb\")\n",
    "\n",
    "        features = {\n",
    "            'secondary_structure': self._analyze_secondary_structure(dssp_dict),\n",
    "            'solvent_accessibility': self._calculate_accessibility(structure),\n",
    "            'packing_density': self._calculate_packing(structure),\n",
    "            'cdr_geometry': self._analyze_cdr_geometry(structure)\n",
    "        }\n",
    "\n",
    "        return features\n",
    "\n",
    "class StructureGuidedGenerator(AntibodyGenerator):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.structure_predictor = StructurePredictor()\n",
    "        self.structural_constraints = StructuralConstraints()\n",
    "\n",
    "    def _evaluate_structure(self, vh: str, vl: str) -> Tuple[float, Dict]:\n",
    "        \"\"\"Evaluate structural quality of a sequence pair\"\"\"\n",
    "        # Predict structure\n",
    "        pdb_str = self.structure_predictor.predict_structure(vh, vl)\n",
    "        if not pdb_str:\n",
    "            return 0.0, {}\n",
    "\n",
    "        # Calculate structural features\n",
    "        features = self.structure_predictor.calculate_structural_features(pdb_str)\n",
    "\n",
    "        # Score structure\n",
    "        structural_score = self._calculate_structural_score(features)\n",
    "\n",
    "        return structural_score, features\n",
    "\n",
    "    def _calculate_structural_score(self, features: Dict) -> float:\n",
    "        \"\"\"Calculate overall structural quality score\"\"\"\n",
    "        score = 1.0\n",
    "\n",
    "        # Check CDR geometry\n",
    "        if features['cdr_geometry']['rmsd'] > self.structural_constraints.max_cdr_rmsd:\n",
    "            score *= 0.5\n",
    "\n",
    "        # Check CDR exposure\n",
    "        if features['solvent_accessibility']['cdr_exposure'] < self.structural_constraints.min_cdr_exposure:\n",
    "            score *= 0.5\n",
    "\n",
    "        # Check packing quality\n",
    "        if features['packing_density']['score'] < self.structural_constraints.min_stability_score:\n",
    "            score *= 0.5\n",
    "\n",
    "        return score\n",
    "\n",
    "    def _fitness_function(self, vh: str, vl: str) -> float:\n",
    "        \"\"\"Enhanced fitness function with structural evaluation\"\"\"\n",
    "        # Get base fitness from property prediction\n",
    "        base_fitness = super()._fitness_function(vh, vl)\n",
    "\n",
    "        # Evaluate structure\n",
    "        structural_score, features = self._evaluate_structure(vh, vl)\n",
    "\n",
    "        # Combine scores\n",
    "        final_fitness = base_fitness * structural_score\n",
    "\n",
    "        return final_fitness\n",
    "\n",
    "    def generate_sequences(self) -> List[Dict]:\n",
    "        \"\"\"Generate sequences with structural analysis\"\"\"\n",
    "        results = super().generate_sequences()\n",
    "\n",
    "        # Add structural analysis\n",
    "        enhanced_results = []\n",
    "        for result in results:\n",
    "            vh, vl = result['VH'], result['VL']\n",
    "\n",
    "            # Predict structure and calculate features\n",
    "            structural_score, features = self._evaluate_structure(vh, vl)\n",
    "\n",
    "            enhanced_results.append({\n",
    "                **result,\n",
    "                'structural_analysis': {\n",
    "                    'score': structural_score,\n",
    "                    'features': features\n",
    "                }\n",
    "            })\n",
    "\n",
    "        return enhanced_results\n",
    "\n",
    "class DeNovoDesigner:\n",
    "    def __init__(self,\n",
    "                 property_model: nn.Module,\n",
    "                 structure_predictor: StructurePredictor,\n",
    "                 config: GenerationConfig):\n",
    "        self.property_model = property_model\n",
    "        self.structure_predictor = structure_predictor\n",
    "        self.config = config\n",
    "\n",
    "    def design_antibody(self,\n",
    "                       target_properties: Dict[str, float],\n",
    "                       structural_constraints: StructuralConstraints,\n",
    "                       num_designs: int = 10) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Design antibodies de novo with target properties\n",
    "\n",
    "        Args:\n",
    "            target_properties: Dict of target property values\n",
    "            structural_constraints: Structural constraints\n",
    "            num_designs: Number of designs to generate\n",
    "\n",
    "        Returns:\n",
    "            List of design candidates with properties and structure\n",
    "        \"\"\"\n",
    "        # Initialize generator with constraints\n",
    "\n",
    "        exp_scaler = StandardScaler()\n",
    "        df = pd.read_csv('../data/merged_antibody_data.csv')\n",
    "        exp_scaler.fit(df[['binding_affinity_kd', 'thermostability_tm1_celsius', 'asec_monomerpct']])\n",
    "\n",
    "        generator = StructureGuidedGenerator(\n",
    "            self.property_model,\n",
    "            self.config,\n",
    "            exp_scaler\n",
    "        )\n",
    "\n",
    "        # Generate candidates\n",
    "        candidates = generator.generate_sequences()\n",
    "\n",
    "        # Filter and rank by closeness to target properties\n",
    "        ranked_candidates = self._rank_candidates(\n",
    "            candidates,\n",
    "            target_properties\n",
    "        )\n",
    "\n",
    "        return ranked_candidates[:num_designs]\n",
    "\n",
    "    def _rank_candidates(self,\n",
    "                        candidates: List[Dict],\n",
    "                        target_properties: Dict[str, float]) -> List[Dict]:\n",
    "        \"\"\"Rank candidates by distance to target properties\"\"\"\n",
    "        for candidate in candidates:\n",
    "            # Calculate distance to target properties\n",
    "            prop_distances = []\n",
    "            for prop, target in target_properties.items():\n",
    "                if prop in candidate['properties']:\n",
    "                    dist = abs(candidate['properties'][prop] - target)\n",
    "                    prop_distances.append(dist)\n",
    "\n",
    "            # Calculate average distance\n",
    "            candidate['target_distance'] = np.mean(prop_distances)\n",
    "\n",
    "        # Sort by distance\n",
    "        return sorted(candidates, key=lambda x: x['target_distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7788c2ca-ccf6-4660-87a3-74a9a311739f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Example usage\n",
    "    config = GenerationConfig(\n",
    "        target_kd=1.0,\n",
    "        target_tm1=75.0,\n",
    "        target_poi=95.0\n",
    "    )\n",
    "\n",
    "    structural_constraints = StructuralConstraints(\n",
    "        max_cdr_rmsd=2.0,\n",
    "        min_cdr_exposure=0.6\n",
    "    )\n",
    "\n",
    "    # Initialize models\n",
    "    property_model = AntibodyTransformer()\n",
    "    property_model.load_state_dict(torch.load('best_model.pth',weights_only=True))\n",
    "    structure_predictor = StructurePredictor()\n",
    "\n",
    "    # Create designer\n",
    "    designer = DeNovoDesigner(\n",
    "        property_model,\n",
    "        structure_predictor,\n",
    "        config\n",
    "    )\n",
    "\n",
    "    # Define target properties\n",
    "    target_properties = {\n",
    "        'KD': 1.0,\n",
    "        'Tm1': 75.0,\n",
    "        'POI': 95.0\n",
    "    }\n",
    "\n",
    "    # Generate designs\n",
    "    designs = designer.design_antibody(\n",
    "        target_properties,\n",
    "        structural_constraints\n",
    "    )\n",
    "\n",
    "    # Print results\n",
    "    for i, design in enumerate(designs, 1):\n",
    "        print(f\"\\nDesign {i}:\")\n",
    "        print(f\"VH: {design['VH']}\")\n",
    "        print(f\"VL: {design['VL']}\")\n",
    "        print(\"\\nPredicted Properties:\")\n",
    "        for prop, value in design['properties'].items():\n",
    "            print(f\"  {prop}: {value:.2f}\")\n",
    "        print(\"\\nStructural Analysis:\")\n",
    "        print(f\"  Score: {design['structural_analysis']['score']:.3f}\")\n",
    "        for feature, value in design['structural_analysis']['features'].items():\n",
    "            print(f\"  {feature}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ab74da-1ff9-4ec1-b72d-d1378d3cd0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "/opt/conda/lib/python3.11/site-packages/ImmuneBuilder/ABodyBuilder2.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(weights_path, map_location=torch.device(self.device)))\n",
      "/opt/conda/lib/python3.11/site-packages/ImmuneBuilder/ABodyBuilder2.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(weights_path, map_location=torch.device(self.device)))\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba2f2845-72cb-41a4-b481-61ba6ea44562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anarci import run_anarci\n",
    "\n",
    "sequence = \"EVQLVESGGGLVQPGGSLRLSCAASGFTFSSYAMSWVRQAPGKGLEWVSAINTKGLTNYADSVKGRFTISRDNSKNTLYLQMNSLRAEDTAVYYCAKGWFDYWGQGTLVTVSS\"\n",
    "numbering = run_anarci([('seq', sequence)], scheme='kabat', output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b92b8a17-300a-4942-b022-1162f32bebe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbering[1][0][0][0][6][0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
